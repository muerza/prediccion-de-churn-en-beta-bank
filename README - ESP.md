# Sure Tomorrow (Sprint 14) â€” Machine Learning + OfuscaciÃ³n de datos ğŸ”ğŸ¤–

Proyecto de *machine learning* para una aseguradora ficticia (**Sure Tomorrow**) con 4 objetivos: bÃºsqueda de clientes similares, clasificaciÃ³n de probabilidad de recibir prestaciones, regresiÃ³n del nÃºmero de prestaciones y una tÃ©cnica de **ofuscaciÃ³n** para proteger datos personales sin perder capacidad de modelado.

---

## Objetivo ğŸ¯

Evaluar si modelos de *machine learning* pueden apoyar al equipo de negocio en:

1. **Encontrar clientes similares** (para marketing y atenciÃ³n comercial) ğŸ”
2. **Predecir si un cliente recibirÃ¡ prestaciones** (clasificaciÃ³n) âœ…/âŒ
3. **Predecir el nÃºmero de prestaciones** que podrÃ­a recibir (regresiÃ³n) ğŸ“ˆ
4. **Proteger datos personales** mediante transformaciÃ³n matemÃ¡tica reversible ğŸ”’

---

## Datos ğŸ“¦

Dataset: `insurance_us.csv`

Columnas usadas:

- `gender`
- `age`
- `income`
- `family_members`
- `insurance_benefits` (objetivo de regresiÃ³n)
- `insurance_benefits_received` (objetivo de clasificaciÃ³n: si recibiÃ³ prestaciones o no)

> Nota: el dataset no se incluye en este repositorio si viene de un entorno del curso. ColÃ³calo en `data/` y ajusta la ruta en el notebook.

---

## Enfoque por tarea ğŸ§©

### 1) Clientes similares (kNN / Nearest Neighbors) ğŸ§­
- Se implementa una funciÃ³n para obtener los **k vecinos mÃ¡s cercanos** usando `NearestNeighbors`.
- Se comparan distancias con diferentes mÃ©tricas (p. ej. Euclidiana / Manhattan).
- Se observa el impacto del **escalado**: sin escalado, variables con valores grandes (como `income`) dominan la distancia.

### 2) ClasificaciÃ³n: Â¿recibirÃ¡ prestaciones? âœ…
- Modelo: `KNeighborsClassifier`.
- Baseline: `DummyClassifier` (para validar si el modelo realmente aprende seÃ±al).
- Se detecta **desbalance de clases** y se aplica **sobremuestreo (upsampling)** para mejorar el aprendizaje.
- MÃ©tricas: **Accuracy, AUC-ROC, F1**.

**Resultados (en el split de prueba del notebook):**
- kNN: Accuracy **0.97**, AUC **1.00**, F1 **0.8825**
- Dummy: Accuracy **0.1127**, AUC **0.50**, F1 **0.2025**
- Mejora de Accuracy: **+0.8573** (â‰ˆ **+85.73 puntos porcentuales**) ğŸš€

### 3) RegresiÃ³n: nÃºmero de prestaciones (Linear Regression) ğŸ“Š
- Se implementa una **RegresiÃ³n Lineal desde cero** (Ã¡lgebra lineal) y se compara contra un enfoque estÃ¡ndar.
- MÃ©tricas: **RMSE** y **RÂ²**.

**Resultados:**
- RMSE **0.333**
- RÂ² **0.413**

### 4) OfuscaciÃ³n de datos (protecciÃ³n sin perder modelado) ğŸ”
- Se genera una matriz aleatoria **invertible** `P` y se transforma `X` con:
  - `X' = X Â· P`
- Se comprueba que la reversiÃ³n es posible con:
  - `X = X' Â· Pâ»Â¹`
- En el notebook se valida la recuperaciÃ³n exacta con `np.allclose(...)=True`.

---

## TecnologÃ­as ğŸ› ï¸

- Python
- NumPy, pandas
- scikit-learn (NearestNeighbors, KNN, mÃ©tricas, train/test split, DummyClassifier)
- (Opcional) seaborn / matplotlib para visualizaciÃ³n ğŸ“‰

---

## CÃ³mo ejecutar â–¶ï¸

1. Crea y activa un entorno virtual
2. Instala dependencias:
   ```bash
   pip install -r requirements.txt
